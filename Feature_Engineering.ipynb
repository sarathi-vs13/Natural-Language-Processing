{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJa7rdDz76N1wWafJvFxIc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarathi-vs13/Natural-Language-Processing/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "aV2yrqwgNiUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "JwCU4HzlNouK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text 1: \"I love NLP\"\n",
        "\n",
        "Text 2: \"I love learning NLP\"\n",
        "\n",
        "Vocabulary: [\"I\", \"love\", \"NLP\", \"learning\"]\n",
        "\n",
        "\n",
        "BoW Representation:\n",
        "\n",
        "Text 1 → [1, 1, 1, 0]\n",
        "\n",
        "Text 2 → [1, 1, 1, 1]\n",
        "\n"
      ],
      "metadata": {
        "id": "PD9STVbXN407"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qSOF4PncNg39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "doc = [\n",
        "    \"I'm learning NLP\",\n",
        "    \"NLP is fun\",\n",
        "    \"Learning NLP\"\n",
        "]\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Learn the vocabulary and transform the documents\n",
        "X = vectorizer.fit_transform(doc)\n",
        "\n",
        "# Convert the result to an array\n",
        "bow_array = X.toarray()\n",
        "\n",
        "print(\"Vocabulary:\", vectorizer.vocabulary_)\n",
        "\n",
        "print(\"BOW Array:\", bow_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqAPRhktOFvH",
        "outputId": "b6fdb489-4792-404d-910d-b8573102d2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'learning': 2, 'nlp': 3, 'is': 1, 'fun': 0}\n",
            "BOW Array: [[0 0 1 1]\n",
            " [1 1 0 1]\n",
            " [0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams"
      ],
      "metadata": {
        "id": "bN7QmicJSz_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"Natural Language Processing is interesting\",\n",
        "    \"I love learning about Language models\"\n",
        "]\n",
        "\n",
        "# Bigrams example\n",
        "\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
        "bigram_matrix = bigram_vectorizer.fit_transform(docs)\n",
        "\n",
        "bigram_array = bigram_matrix.toarray()\n",
        "\n",
        "print(\"Bigram Vocabulary:\", bigram_vectorizer.vocabulary_)\n",
        "\n",
        "print(\"Bigarm Array:\", bigram_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGzEwkROS0mP",
        "outputId": "bc0f9933-fbf3-47a5-897f-0f99566106f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Vocabulary: {'natural language': 6, 'language processing': 3, 'processing is': 7, 'is interesting': 1, 'love learning': 5, 'learning about': 4, 'about language': 0, 'language models': 2}\n",
            "Bigarm Array: [[0 1 0 1 0 0 1 1]\n",
            " [1 0 1 0 1 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigrams example\n",
        "\n",
        "trigram_vectorizer = CountVectorizer(ngram_range=(3,3))\n",
        "trigram_matrix = trigram_vectorizer.fit_transform(docs)\n",
        "\n",
        "trigram_array = trigram_matrix.toarray()\n",
        "\n",
        "print(\"Trigram Vocabulary:\", trigram_vectorizer.vocabulary_)\n",
        "\n",
        "print(\"Trigram Array:\", trigram_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geVmQcfdUYzE",
        "outputId": "d81df510-ae09-48d8-db56-a838c31fd37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Vocabulary: {'natural language processing': 4, 'language processing is': 1, 'processing is interesting': 5, 'love learning about': 3, 'learning about language': 2, 'about language models': 0}\n",
            "Trigram Array: [[0 1 0 0 1 1]\n",
            " [1 0 1 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "K_zE5aPgdbnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
        "\n",
        "corpus = [\n",
        "    \"Natural Language Processing is interesting\",\n",
        "    \"I love learning about Language models\",\n",
        "    \"I love NLP\",\n",
        "    \"NLP is fun\",\n",
        "    \"I love machine learning\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"=\" * 100)\n",
        "\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "3G9cUV_hVIx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5448709e-9cd1-424c-c6ae-67113fe8d62f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['about' 'fun' 'interesting' 'is' 'language' 'learning' 'love' 'machine'\n",
            " 'models' 'natural' 'nlp' 'processing']\n",
            "====================================================================================================\n",
            "[[0.         0.         0.48214012 0.38898761 0.38898761 0.\n",
            "  0.         0.         0.         0.48214012 0.         0.48214012]\n",
            " [0.51637397 0.         0.         0.         0.41660727 0.41660727\n",
            "  0.34582166 0.         0.51637397 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.63871058 0.         0.         0.         0.76944707 0.        ]\n",
            " [0.         0.659118   0.         0.53177225 0.         0.\n",
            "  0.         0.         0.         0.         0.53177225 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.55681615\n",
            "  0.4622077  0.69015927 0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4WOftv7eeciW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}